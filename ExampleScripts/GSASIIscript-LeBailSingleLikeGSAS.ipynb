{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PySPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following tutorial at\n",
    "# https://gsas-ii.readthedocs.io/en/latest/GSASIIscriptable.html#peak-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd  # AC got a 'no module named pandas' error.  Do we need it?\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Eventually we'll have to find a common pathway, for now just change if this is commented out.\n",
    "\n",
    "if re.search('dtn1',os.getcwd()) is not None:\n",
    "    print(\"David's computer\")\n",
    "    sys.path.insert(0,'/Users/dtn1/gsas2full/GSASII/') # needed to \"find\" GSAS-II modules\n",
    "\n",
    "elif re.search('creuzige',os.getcwd()) is not None:\n",
    "    print(\"Adam's computer\")\n",
    "    sys.path.insert(0,'/Users/creuzige/gsas2full/envs/gsas-AustCalc/GSASII/') # needed to \"find\" GSAS-II modules\n",
    "# Note difference between paths\n",
    "#    sys.path.insert(0,'/Users/creuzige/gsas2full/envs/gsas2pkg/GSASII/') # needed to \"find\" GSAS-II modules\n",
    "    \n",
    "    \n",
    "elif re.search('maxgarman', os.getcwd()) is not None:\n",
    "    print(\"Max's Computer\")\n",
    "    sys.path.insert(0, '../opt/anaconda3/GSASII')\n",
    "\n",
    "import GSASIIscriptable as G2sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx=G2sc.G2Project(os.path.join('..','server_workdir','pkfit.gpx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=gpx.histograms()\n",
    "h[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScriptDirectory=os.getcwd()\n",
    "GitLabDirectory=os.path.dirname(os.getcwd())\n",
    "ExampleDataDirectory=os.path.join(GitLabDirectory,\"ExampleData\",\"Example01\")\n",
    "SaveDataDirectory=os.path.join(GitLabDirectory,\"SaveData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GitLabDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datadir = os.path.expanduser(ExampleDataDirectory)\n",
    "SaveDir= os.path.expanduser(SaveDataDirectory)\n",
    "DataPathWrap = lambda fil: os.path.join(datadir,fil)\n",
    "SaveWrap = lambda fil: os.path.join(SaveDir,fil)\n",
    "gpx = G2sc.G2Project(newgpx=SaveWrap('pkfit.gpx'))\n",
    "hist = gpx.add_powder_histogram(DataPathWrap('Gonio_BB-HD-Cu_Gallipix3d[30-120]_New_Control_proper_power.xrdml'),\n",
    "                                DataPathWrap('TestCalibration.instprm'), # need to get a \n",
    "                                fmthint='Panalytical xrdml (xml)', databank=1, instbank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data structure.\n",
    "# For more details see the developers documentation \n",
    "# https://gsas-ii.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ScriptDirectory=os.getcwd()\n",
    "# GitLabDirectory=os.path.dirname(os.getcwd())\n",
    "# ExampleDataDirectory=os.path.join(GitLabDirectory,\"ExampleData/Example01\")\n",
    "# SaveDataDirectory=os.path.join(GitLabDirectory,\"SaveData\")\n",
    "\n",
    "# datadir = os.path.expanduser(ExampleDataDirectory)\n",
    "# SaveDir= os.path.expanduser(SaveDataDirectory)\n",
    "# DataPathWrap = lambda fil: os.path.join(datadir,fil)\n",
    "# SaveWrap = lambda fil: os.path.join(SaveDir,fil)\n",
    "# gpx = G2sc.G2Project(newgpx=SaveWrap('pkfit.gpx'))\n",
    "# hist = gpx.add_powder_histogram(DataPathWrap('Gonio_BB-HD-Cu_Gallipix3d[30-120]_New_Control_proper_power.xrdml'),\n",
    "#                                 DataPathWrap('TestCalibration.instprm'), # need to get a \n",
    "#                                 fmthint='Panalytical xrdml (xml)', databank=1, instbank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hist.data['data'][0]['hId']\n",
    "#hist.data['Comments']\n",
    "#hist['data']['hId'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(hist.data['data']) # 3 objects\n",
    "\n",
    "#hist.data['data'][0] # dict: with some kind of meta-info?\n",
    "#hist.data['data'][1] # np.array: see below\n",
    "#hist.data['data'][2] # string: file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From: https://gsas-ii.readthedocs.io/en/latest/GSASIIobj.html?highlight=Powder%20Diffraction%20Tree#powder-diffraction-tree-items\n",
    "    \n",
    "    Data \t\t\n",
    "\n",
    "(list) The data consist of a list of 6 np.arrays containing in order:\n",
    "\n",
    "    the x-postions (two-theta in degrees),\n",
    "    the intensity values (Yobs),\n",
    "    the weights for each Yobs value\n",
    "    the computed intensity values (Ycalc)\n",
    "    the background values\n",
    "    Yobs-Ycalc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][1])\n",
    "plt.xlabel(\"2theta\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add phases to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhaseAustenite = gpx.add_phase(DataPathWrap(\"austenite-Duplex.cif\"),\n",
    "         phasename=\"Austenite\",fmthint='CIF')\n",
    "\n",
    "PhaseFerrite = gpx.add_phase(DataPathWrap(\"ferrite-Duplex.cif\"),\n",
    "         phasename=\"Ferrite\",fmthint='CIF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Guess locations for peaks based on lattice parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the lattice parameter \n",
    "#a0_Austenite=PhaseAustenite.data['General']['Cell'][1]\n",
    "#a0_Ferrite=PhaseFerrite.data['General']['Cell'][1]\n",
    "\n",
    "# Fit values to check if the Peak Extraction has better luck\n",
    "a0_Austenite=3.600\n",
    "a0_Ferrite=2.8762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ka1 wavelength\n",
    "# hist.data['Comments']\n",
    "\n",
    "Ka1_wavelength=float([s for s in hist.data['Comments'] if s.startswith('Ka1')][0].split('=')[1])\n",
    "\n",
    "# Hardcode for testing\n",
    "#Ka1_wavelength=2.29092 # Cr wavelength for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate locations of peaks from .cif file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bragg diffraction\n",
    "n * lambda=2 * d * sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardcoding HKL lists for now, likely better ways to do this later...\n",
    "HKL_BCC=[[1,1,0],[2,0,0],[2,1,1],[2,2,0],[3,1,0],[2,2,2],[3,2,1],[4,1,1]]\n",
    "HKL_FCC=[[1,1,1],[2,0,0],[2,2,0],[3,1,1],[2,2,2],[4,0,0],[3,3,1],[4,2,0],[4,2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hkl in HKL_BCC:\n",
    "#    d=(a0_Ferrite/ math.sqrt(hkl[0]*hkl[0]+hkl[1]*hkl[1]+hkl[2]*hkl[2]))   \n",
    "    \n",
    "d_BCC=[a0_Ferrite/ math.sqrt(hkl[0]*hkl[0]+hkl[1]*hkl[1]+hkl[2]*hkl[2]) for hkl in HKL_BCC]\n",
    "SinTheta_BCC=[1*Ka1_wavelength/(2*d) for d in d_BCC]\n",
    "\n",
    "d_FCC=[a0_Austenite/ math.sqrt(hkl[0]*hkl[0]+hkl[1]*hkl[1]+hkl[2]*hkl[2]) for hkl in HKL_FCC]\n",
    "SinTheta_FCC=[1*Ka1_wavelength/(2*d) for d in d_FCC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_BCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of 2Theta values from the dspacing and wavelength. Mark any non-physical values with np.nan\n",
    "TwoTheta_BCC=[np.nan]*len(SinTheta_BCC)\n",
    "for i,value in enumerate(SinTheta_BCC):\n",
    "    #print(value)\n",
    "    try:\n",
    "        TwoTheta_BCC[i]=(2*math.degrees(math.asin(value)))\n",
    "    except:\n",
    "        TwoTheta_BCC[i]=(np.nan)\n",
    "#print(TwoTheta_BCC)\n",
    "#print(HKL_BCC)       \n",
    "        \n",
    "TwoTheta_FCC=[np.nan]*len(SinTheta_FCC)\n",
    "for i,value in enumerate(SinTheta_FCC):\n",
    "    #print(value)\n",
    "    try:\n",
    "        TwoTheta_FCC[i]=(2*math.degrees(math.asin(value)))\n",
    "    except:\n",
    "        TwoTheta_FCC[i]=(np.nan)\n",
    "#print(TwoTheta_FCC)\n",
    "#print(HKL_FCC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of TwoTheta in the data range\n",
    "#print(max(hist.data['data'][1][0]))\n",
    "\n",
    "TwoThetaInRange_BCC=[np.nan if i > max(hist.data['data'][1][0]) else i for i in TwoTheta_BCC]\n",
    "TwoThetaInRange_BCC=[np.nan if i < min(hist.data['data'][1][0]) else i for i in TwoThetaInRange_BCC]\n",
    "\n",
    "TwoThetaInRange_FCC=[np.nan if i > max(hist.data['data'][1][0]) else i for i in TwoTheta_FCC]\n",
    "TwoThetaInRange_FCC=[np.nan if i < min(hist.data['data'][1][0]) else i for i in TwoThetaInRange_FCC]\n",
    "\n",
    "\n",
    "#print(TwoTheta_FCC)\n",
    "#print(TwoThetaInRange_FCC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PeaksList=[]\n",
    "PeaksList = np.array(TwoThetaInRange_BCC)[~np.isnan(np.array(TwoThetaInRange_BCC))]\n",
    "PeaksList = np.concatenate((PeaksList,\n",
    "                           np.array(TwoThetaInRange_FCC)[~np.isnan(np.array(TwoThetaInRange_FCC))]),\n",
    "                           axis=0)\n",
    "PeaksList=list(PeaksList)\n",
    "# Don't sort, it actually makes keeping track of the different items harder...\n",
    "# PeaksList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PeaksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIF is slightly off, kludge for now...\n",
    "# Likely need to refine, adjust lattice parameters and start over again with peaks with non-negative intensities\n",
    "# Or fix the negative intensities...\n",
    "PeaksList=[x+0.5 for x in PeaksList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the peak list in case of errors...\n",
    "hist.Peaks['peaks']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add controls for number of cycles?\n",
    "\n",
    "hist.set_refinements({'Background': {\"no. coeffs\": 5,'type': 'chebyschev-1', 'refine': True}})\n",
    "hist.refine_peaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hist.data['data'][1][0], hist.data['data'][1][1], label='data', color='0.7')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][4], label='background', color='r')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][3], label='fit', color='b')\n",
    "plt.xlabel(\"2theta\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a few peaks to the list\n",
    "\n",
    "- It seems like the peak positions are slightly off from the .cif file (about 0.4°)\n",
    "- This results in negative intensities for some of the higher peaks\n",
    "- Maybe look for maxima?  Or a series of fit sequences?\n",
    "- Error check negative peaks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for peak in PeaksList[0:5]:\n",
    "for peak in PeaksList:\n",
    "    hist.add_peak(1, ttheta=peak)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Need to use this order, otherwise fitting gets unstable\n",
    "hist.set_peakFlags(pos=False,area=True,sig=False,gam=False )\n",
    "hist.refine_peaks(mode='useIP')\n",
    "\n",
    "# Resetting the value doesn't seem to work...\n",
    "# for i,value in enumerate(hist.Peaks['peaks']):\n",
    "#     print(value[2])\n",
    "#     if value[2]<0:\n",
    "#         print(hist.Peaks['peaks'][i][2],-value[2])\n",
    "#         hist.Peaks['peaks'][i][2]=-value[2]\n",
    "        \n",
    "# hist.set_peakFlags(pos=True)\n",
    "# hist.refine_peaks('hold')\n",
    "        \n",
    "hist.set_peakFlags(pos=True,area=True,sig=False,gam=False)\n",
    "hist.refine_peaks(mode='useIP')\n",
    "hist.set_peakFlags(pos=True,area=True,sig=True,gam=False)\n",
    "hist.refine_peaks(mode='useIP')\n",
    "hist.set_peakFlags(pos=True,area=True,sig=False,gam=True)\n",
    "hist.refine_peaks(mode='hold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist.data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.data['Peak Fit Rvals']['GOF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist.set_peakFlags(area=True,pos=True,sig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlim([40,120])\n",
    "\n",
    "plt.scatter(hist.data['data'][1][0], hist.data['data'][1][1], label='data', color='0.7')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][4], label='background', color='r')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][3], label='fit', color='b')\n",
    "plt.xlabel(\"2theta\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlim([44,45])\n",
    "\n",
    "plt.scatter(hist.data['data'][1][0], hist.data['data'][1][1], label='data', color='0.7')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][4], label='background', color='r')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][3], label='fit', color='b')\n",
    "plt.xlabel(\"2theta\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['peaks'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,value in enumerate(hist.Peaks['peaks']):\n",
    "    print(value[2])\n",
    "    if value[2]<0:\n",
    "        print(hist.Peaks['peaks'][i][2],-value[2])\n",
    "        hist.Peaks['peaks'][i][2]=-value[2]\n",
    "# hist.PeakList[0][0]=0\n",
    "print(hist.PeakList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,value in enumerate(hist.PeakList):\n",
    "    print(value[1])\n",
    "    if value[1]<0:\n",
    "        print(hist.PeakList[i][1],-value[1])\n",
    "        hist.PeakList[i][1]=-value[1]\n",
    "hist.PeakList[0][0]=0\n",
    "print(hist.PeakList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine background values\n",
    "\n",
    "- Using fit/data counts over the range risks including nearby peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for peak in hist.data['Peak List']['peaks']:\n",
    "    print(peak)\n",
    "    print(peak[0], 4*peak[4]/100)\n",
    "    x_min=peak[0]- 4*peak[4]/100\n",
    "    x_max=peak[0]+4*peak[4]/100\n",
    "    \n",
    "    indexes = [index for index, value in enumerate(hist.data['data'][1][0]) if value > x_min and value < x_max ]\n",
    "\n",
    "    back_counts=0\n",
    "    data_counts=0\n",
    "    fit_counts=0\n",
    "    \n",
    "    for index in indexes:\n",
    "    \n",
    "        back_counts=back_counts+hist.data['data'][1][4][index]\n",
    "        fit_counts=fit_counts+hist.data['data'][1][3][index]\n",
    "        data_counts=data_counts+hist.data['data'][1][1][index]\n",
    "        # print(index, hist.data['data'][1][0][index],hist.data['data'][1][4][index])\n",
    "    #print(peak[2],back_counts,peak[2]/back_counts,\"\\n\")\n",
    "    print(peak[2]/math.sqrt(back_counts+peak[2]))\n",
    "    print(peak[2],back_counts,back_counts+peak[2], math.sqrt(back_counts+peak[2]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.data['data'][1][0], hist.data['data'][1][4],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the lattice parameter a_0 from fit data\n",
    "Added 2021 Apr 01 - AC\n",
    "\n",
    "\n",
    "*We should probably work out data structures before too long*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the hkls in range (may not be the ones fit, need to check)\n",
    "\n",
    "#TwoThetaInRange_BCC\n",
    "#HKL_BCC\n",
    "\n",
    "#Merged with BCC, then FCC\n",
    "hkl_list=[]\n",
    "for i,row in enumerate(TwoThetaInRange_BCC):\n",
    "    if np.isfinite(row):\n",
    "        hkl_list.append(HKL_BCC[i])\n",
    "for i,row in enumerate(TwoThetaInRange_FCC):\n",
    "    if np.isfinite(row):\n",
    "        hkl_list.append(HKL_FCC[i])\n",
    "        \n",
    "dspace_list=[]\n",
    "for row in hkl_list:\n",
    "    dspace_list.append(math.sqrt(row[0]*row[0]+row[1]*row[1]+row[2]*row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hkl_list\n",
    "dspace_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 2theta position\n",
    "hist.Peaks['peaks']\n",
    "FitPos=[row[0] for row in hist.Peaks['peaks']] # only way to access column in list of lists\n",
    "\n",
    "# Merge to determine the hkl\n",
    "\n",
    "\n",
    "a0_list=[]\n",
    "# probably should check if the lengths are the same\n",
    "if len(FitPos) == len(dspace_list):\n",
    "    for i,row in enumerate(FitPos):\n",
    "        #row/2.0 since row is 2theta...\n",
    "        a0_list.append((Ka1_wavelength*dspace_list[i])/(2*math.sin(math.radians(row/2.0))))\n",
    "        print(row,math.sin(math.radians(row/2.0)),dspace_list[i],a0_list[i])\n",
    "else:\n",
    "    print(\"These are not the same length\")\n",
    "\n",
    "# \n",
    "#n * lambda=2 * d * sin(theta)\n",
    "#Ka1_wavelength\n",
    "\n",
    "#[2*math.sin(math.radians(row))* for row in FitPos]\n",
    "\n",
    "#hist.Peaks['sigDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like it does things in order, but not verified...\n",
    "pos_keys=[key for key, value in hist.Peaks['sigDict'].items() if 'pos' in key]\n",
    "\n",
    "FitPos_uncert=[]\n",
    "for name in pos_keys:\n",
    "    FitPos_uncert.append(hist.Peaks['sigDict'][name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper and lower bounds on uncertainties\n",
    "a0_uncert_LB=[]\n",
    "a0_uncert_UB=[]\n",
    "if len(FitPos_uncert) == len(dspace_list):\n",
    "    for i,row in enumerate(FitPos_uncert):\n",
    "        #row/2.0 since row is 2theta...\n",
    "        a0_uncert_UB.append((Ka1_wavelength*dspace_list[i])/(2*math.sin(math.radians((FitPos[i]+row)/2.0))))\n",
    "        a0_uncert_LB.append((Ka1_wavelength*dspace_list[i])/(2*math.sin(math.radians((FitPos[i]-row)/2.0))))\n",
    "        #print(row,math.sin(math.radians(row/2.0)),dspace_list[i],a0_list[i])\n",
    "else:\n",
    "    print(\"These are not the same length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a0_uncert_LB)\n",
    "\n",
    "print(a0_list)\n",
    "\n",
    "print(a0_uncert_UB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['sigDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe fit entire pattern for lattice parameters, then try peakfitting?\n",
    "- Seems like it works ok in the GUI, but need to allow the phase fraction to be refined (only on one)\n",
    "- Add constraint, (austenite + ferrite  =1) 0:0:scale, 1:0:scale\n",
    "- Need to refine both with the constraint enabled.  \n",
    "- weight fracitons are quite different than the phase fractions (lattice cell dimensions?)\n",
    "- Over estimation of the peak hights at first, then underestimate later\n",
    "- austenite=3.60097, ferrite=2.87564\n",
    "- Tried these parameters, had worse luck fitting...\n",
    "- Maybe use the scale factor from the sample parameters to get the areas close?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working properly yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('peak positions: ',[i[0] for i in hist.PeakList])\n",
    "# for i in range(len(hist.Peaks['peaks'])):\n",
    "#     print('peak',i,'pos=',hist.Peaks['peaks'][i][0],'sig=',hist.Peaks['sigDict']['pos'+str(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for peak in PeaksList:\n",
    "#     hist.add_peak(1, ttheta=peak)\n",
    "# hist.set_peakFlags(area=True,pos=True,sig=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pattern simulation, extract intensities from that?\n",
    "https://gsas-ii.readthedocs.io/en/latest/GSASIIscriptable.html#pattern-simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx = G2sc.G2Project(newgpx=SaveWrap('Austenite-sim.gpx')) # create a project    \n",
    "\n",
    "PhaseAustenite = gpx.add_phase(DataPathWrap(\"austenite-Duplex.cif\"),\n",
    "         phasename=\"Austenite\",fmthint='CIF')\n",
    "\n",
    "#PhaseFerrite = gpx.add_phase(DataPathWrap(\"ferrite-Duplex.cif\"),\n",
    "#         phasename=\"Ferrite\",fmthint='CIF')\n",
    "\n",
    "histogram_scale=100.\n",
    "\n",
    "# add a simulated histogram and link it to the previous phase(s)\n",
    "hist1 = gpx.add_simulated_powder_histogram(\"Austenite simulation\",\n",
    "            DataPathWrap('TestCalibration.instprm'),5.,120.,Npoints=5000,\n",
    "            phases=gpx.phases(),scale=histogram_scale)\n",
    "gpx.do_refinements()   # calculate pattern\n",
    "gpx.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([40,120])\n",
    "\n",
    "plt.plot(hist1.data['data'][1][0], hist1.data['data'][1][1])\n",
    "plt.xlabel(\"2theta\")\n",
    "plt.ylabel(\"intensity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical intensities are included in the Reflection Lists\n",
    "- see line ~817 in GSASIIobs.py for the full description of the reflection lists\n",
    "columns 0,1,2: h,k,l\n",
    "column 5: 2-theta\n",
    "column 9: Calculated structure factor squared (inludes anamolous scattering and thermal parameters?)\n",
    "column 11: Intensity correction (scales, polarization, preferred orientation, absorbtion, extinction)\n",
    "\n",
    "It's not clear where thermal parameters or the unit cell volume come in.\n",
    "Also not clear where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.data['Reflection Lists']['Austenite']['RefList'][:,9]*hist1.data['Reflection Lists']['Austenite']['RefList'][:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.data['Reflection Lists']['Austenite']['RefList'][:,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array of the strucutre factors and intensity corrections (theoretical intensities?) for this material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.data['Reflection Lists']['Austenite']['RefList'][:,9] * hist1.data['Reflection Lists']['Austenite']['RefList'][:,11] / histogram_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.data['Reflection Lists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhaseAustenite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx = G2sc.G2Project(newgpx=SaveWrap('Ferrite-sim.gpx')) # create a project    \n",
    "\n",
    "PhaseFerrite = gpx.add_phase(DataPathWrap(\"ferrite-Duplex.cif\"),\n",
    "         phasename=\"Ferrite\",fmthint='CIF')\n",
    "\n",
    "#PhaseFerrite = gpx.add_phase(DataPathWrap(\"ferrite-Duplex.cif\"),\n",
    "#         phasename=\"Ferrite\",fmthint='CIF')\n",
    "\n",
    "# add a simulated histogram and link it to the previous phase(s)\n",
    "hist2 = gpx.add_simulated_powder_histogram(\"Ferrite simulation\",\n",
    "            DataPathWrap('TestCalibration.instprm'),5.,120.,Npoints=1000,\n",
    "            phases=gpx.phases(),scale=500000.)\n",
    "gpx.do_refinements()   # calculate pattern\n",
    "gpx.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used the GUI to investigate this data a bit more.  \n",
    "- Peakfits like I did above seem to work ok.  \n",
    "- Values of integrated intensity are closest to the I100 column of the reflection lists\n",
    "- Intensities and F values between this and the magic spreadsheet don't agree\n",
    "- Compositions are slightly different. Only wt% used in magic spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Have not edited below this for austenite calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist=[2.0923, 2.0923-0.05, 2.0923+0.05]\n",
    "TOFlist=[]\n",
    "for i in dlist:\n",
    "    print(TOF_calc(i,16324.50,6.86,0.00))\n",
    "    TOFlist.append(TOF_calc(i,16324.50,6.86,0.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.xlim(TOFlist[1],TOFlist[2])\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OutputData(hist, append, Tick, LowLimit, HighLimit):\n",
    "    # plot fit and difference\n",
    "    plt.figure(figsize=[10,8])\n",
    "    plt.scatter(hist.data['data'][1][0], hist.data['data'][1][1],color='k',label='Data')\n",
    "    plt.plot(hist.data['data'][1][0], hist.data['data'][1][3],color='b',label='Computed Intensity')\n",
    "    plt.plot(hist.data['data'][1][0], hist.data['data'][1][5],'-o',color='g',label='Difference')\n",
    "    # vertical line for place of intial guess\n",
    "    plt.vlines(Tick,0,plt.gca().get_ylim()[0]*0.5)\n",
    "    # horizontal line to benchmark difference plot\n",
    "    plt.hlines(0,plt.gca().get_xlim()[0],plt.gca().get_xlim()[1],'0.7')\n",
    "    plt.xlim(LowLimit, HighLimit)\n",
    "    plt.legend()\n",
    "    # option to view on screen\n",
    "    #plt.show()\n",
    "    # option to save the plot\n",
    "    plt.savefig(\"GSASPeakFit-\"+append+\".png\", dpi=300)\n",
    "\n",
    "    keys = hist.Peaks['sigDict'].keys()\n",
    "    #print(keys)\n",
    "    with open(\"GSASPeakFit-\"+append+\".csv\",'a') as fd:\n",
    "        wr=csv.writer(fd)\n",
    "        dwr=csv.DictWriter(fd, keys)\n",
    "\n",
    "        wr.writerow(['# TOF position (pos)', 'Area (int)','Alpha (alp)','Beta (bet)','Sigma (sig)','Gamma (gam)'])\n",
    "        wr.writerow(['# Peak Parameter List'])\n",
    "        wr.writerow(['# Peak Parameter Flags'])\n",
    "        wr.writerow(hist.Peaks['peaks'][0][0::2])\n",
    "        wr.writerow(hist.Peaks['peaks'][0][1::2])\n",
    "        wr.writerow([\"########################\"])\n",
    "        wr.writerow(['# Background Values'])\n",
    "        wr.writerow(hist['Background'][0][3:])\n",
    "        wr.writerow([\"########################\"])\n",
    "        wr.writerow(['# SigDict Keys'])\n",
    "        wr.writerow(['# SigDict Values'])\n",
    "        dwr.writeheader()\n",
    "        dwr.writerows([hist.Peaks['sigDict']])\n",
    "        wr.writerow([\"########################\"])\n",
    "        wr.writerow(['# Covariance Matrix'])\n",
    "        wr.writerows(np.array(hist['Peak Fit Result'][1]))\n",
    "        wr.writerow([\"########################\"])        \n",
    "        wr.writerow(['# Correlation Matrix'])\n",
    "        wr.writerows(np.corrcoef(hist['Peak Fit Result'][1]))\n",
    "        wr.writerow([\"########################\"])        \n",
    "        wr.writerow(['# Reduced ChiSq (GOF)'])\n",
    "        wr.writerow([hist.data['Peak Fit Rvals']['GOF']])\n",
    "        wr.writerow([\"########################\"])   \n",
    "        wr.writerow(['# Dspacing (1 term) -/+ (3 terms)'])\n",
    "        try:\n",
    "            d=Dspace_calc(hist.Peaks['peaks'][0][0],16324.50,6.86,0.00)\n",
    "            d_minus=Dspace_calc(hist.Peaks['peaks'][0][0]-hist.Peaks['sigDict']['pos0'],16324.50,6.86,0.00)\n",
    "            d_plus=Dspace_calc(hist.Peaks['peaks'][0][0]+hist.Peaks['sigDict']['pos0'],16324.50,6.86,0.00)\n",
    "            wr.writerow([d,d_minus,d_plus])\n",
    "            wr.writerow([d,d-d_minus,d_plus-d])\n",
    "        except:\n",
    "            wr.writerow([Dspace_calc(hist.Peaks['peaks'][0][0],16324.50,6.86,0.00)])             \n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hist.Peaks['peaks'])):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['Background'][0][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['peaks'][0][0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['sigDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OutputData(hist, \"\", TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "# Doesn't work well prior to fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence 1, following Rawplot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define peaks to fit\n",
    "#Limit is between the 422 and 333 peaks\n",
    "\n",
    "hist.set_refinements({'Limits': [TOFlist[1],TOFlist[2]],  \n",
    "      'Background': {\"no. coeffs\": 2,'type': 'chebyschev-1', 'refine': True}\n",
    "                     })\n",
    "# TOF data isn't listed right now.\n",
    "peak1 = hist.add_peak(1, dspace=2.0923)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Following Rawplot method (seq1)\n",
    "\n",
    "#area alone doesn't work well, since there is no positions\n",
    "hist.set_peakFlags(area=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step1-Area\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#\n",
    "hist.set_peakFlags(area=0,pos=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step2-Pos\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "hist.set_peakFlags(area=True,pos=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step3-Pos-Area\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#These don't change sigma and gamma, but they do change alpha and beta...\n",
    "\n",
    "hist.set_peakFlags(area=True, pos=0, sig=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step4-Area-Sig\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#hist.set_peakFlags(area=True, pos=True, gam=True)\n",
    "#hist.refine_peaks()\n",
    "\n",
    "hist.set_peakFlags(area=0, pos=0, sig=0, gam=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step5-Gam\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "hist.set_peakFlags(area=True, pos=True, sig=True, gam=0)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq1-Step6-Area-Pos-Sig\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "\n",
    "\n",
    "# hist.set_peakFlags(area=True, pos=True,alp=True,bet=True, sig=True, gam=True)\n",
    "# hist.refine_peaks()\n",
    "# OutputData(hist, \"Seq-Area-Pos-Sig-Gam-Alp-Bet\",TOFlist[0],TOFlist[1],TOFlist[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence 2 (Single background; alpha and beta refined, not gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define peaks to fit\n",
    "#Limit is between the 422 and 333 peaks\n",
    "\n",
    "hist.set_refinements({'Limits': [TOFlist[1],TOFlist[2]],  \n",
    "      'Background': {\"no. coeffs\": 1,'type': 'chebyschev-1', 'refine': True}\n",
    "                     })\n",
    "# TOF data isn't listed right now.\n",
    "peak1 = hist.add_peak(1, dspace=2.0923)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Following Rawplot method (seq2)\n",
    "\n",
    "#area alone doesn't work well, since there is no positions\n",
    "hist.set_peakFlags(area=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step1-Area\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#\n",
    "hist.set_peakFlags(area=0,pos=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step2-Pos\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "hist.set_peakFlags(area=True,pos=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step3-Pos-Area\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#These don't change sigma and gamma, but they do change alpha and beta...\n",
    "\n",
    "hist.set_peakFlags(area=True, pos=0, sig=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step4-Area-Sig\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "#hist.set_peakFlags(area=True, pos=True, gam=True)\n",
    "#hist.refine_peaks()\n",
    "\n",
    "hist.set_peakFlags(area=0, pos=0, sig=0, alp=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step5-Alp\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "hist.set_peakFlags(alp=0, bet=True)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step6-Bet\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "hist.set_peakFlags(area=True, pos=True, sig=True, bet=0)\n",
    "hist.refine_peaks()\n",
    "OutputData(hist, \"Seq2-Step7-Area-Pos-Sig\",TOFlist[0],TOFlist[1],TOFlist[2])\n",
    "\n",
    "\n",
    "\n",
    "# hist.set_peakFlags(area=True, pos=True,alp=True,bet=True, sig=True, gam=True)\n",
    "# hist.refine_peaks()\n",
    "# OutputData(hist, \"Seq-Area-Pos-Sig-Gam-Alp-Bet\",TOFlist[0],TOFlist[1],TOFlist[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx.get_Covariance(['0:0:Back;0','0:0:Back;1','0:0:pos0','0:0:int0','sig0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['Background']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['Peak Fit Result'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(hist['Peak Fit Result'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nothing run below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['sigDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'C' in hist.data['Instrument Parameters'][0]['Type'][0]:\n",
    "    print(\"hi\")\n",
    "else:\n",
    "    print(\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.data['Peak Fit Rvals']['GOF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.set_peakFlags(area=True, pos=True, sig=True)\n",
    "hist.refine_peaks()\n",
    "hist.set_peakFlags(area=True, pos=True, gam=True)\n",
    "hist.refine_peaks()\n",
    "hist.set_peakFlags(area=True, pos=True, sig=True, gam=True)\n",
    "hist.refine_peaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('peak positions: ',[i[0] for i in hist.PeakList])\n",
    "for i in range(len(hist.Peaks['peaks'])):\n",
    "    print('peak',i,'pos=',hist.Peaks['peaks'][i][0],'sig=',hist.Peaks['sigDict']['pos'+str(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.Peaks['sigDict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit peaks\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][3],label='Computed Intensity')\n",
    "plt.xlim(11752.,40000.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit difference\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][1],color='k',label='Data')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][3],color='b',label='Computed Intensity')\n",
    "plt.plot(hist.data['data'][1][0], hist.data['data'][1][5],color='g',label='Difference')\n",
    "plt.xlim(11752.,40000.)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hist.Peaks['peaks'])):\n",
    "    print('peak',i)\n",
    "    print('TOF pos=',hist.Peaks['peaks'][i][0],'sig=',hist.Peaks['sigDict']['pos'+str(i)])\n",
    "    print('Dspace pos=', Dspace_calc(hist.Peaks['peaks'][i][0],16324.50,6.86,0.00),\n",
    "          'sig (pos)=',Dspace_calc(hist.Peaks['peaks'][i][0]+hist.Peaks['sigDict']['pos'+str(i)],16324.50,6.86,0.00)-\n",
    "          Dspace_calc(hist.Peaks['peaks'][i][0],16324.50,6.86,0.00),\n",
    "          'sig (neg)=',Dspace_calc(hist.Peaks['peaks'][i][0],16324.50,6.86,0.00)-\n",
    "          Dspace_calc(hist.Peaks['peaks'][i][0]-hist.Peaks['sigDict']['pos'+str(i)],16324.50,6.86,0.00))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.Peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From GSASIIscriptable.py, lines 4007\n",
    "\n",
    "        :returns: dict with two elements where item\n",
    "          'peaks' is a list of peaks where each element is \n",
    "          [pos,pos-ref,area,area-ref,sig,sig-ref,gam,gam-ref], \n",
    "          where the -ref items are refinement flags and item\n",
    "          'sigDict' is a dict with possible items 'Back;#', \n",
    "          'pos#', 'int#', 'sig#', 'gam#'\n",
    "          \n",
    "Fitting output lists:pos       esd       int       esd      alp     esd     bet     esd      sig       esd       gam       esd      bins\n",
    "\n",
    "The fitting output values correspond to the column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(hist.Peaks)\n",
    "HistDF=pd.DataFrame(hist.Peaks['peaks'], columns=['pos','pos-ref','area','area-ref','alph',\n",
    "                                                  'alph-ref','bet','bet-ref','Sig','Sig-ref',\n",
    "                                                  'Gam','gam-ref'])\n",
    "print(HistDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.Peaks['sigDict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SigDF=pd.DataFrame(hist.Peaks['sigDict'])#, columns=['pos','pos-ref','area','area-ref','alph',\n",
    "                                            #      'alph-ref','bet','bet-ref','Sig','Sig-ref',\n",
    "                                            #      'Gam','gam-ref'])\n",
    "print(SigDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataList=[]\n",
    "for i in range(len(hist.Peaks['peaks'])):\n",
    "    #print('peak',i)\n",
    "    #print('TOF pos=',hist.Peaks['peaks'][i][0],'sig=',hist.Peaks['sigDict']['pos'+str(i)])\n",
    "    DataList.append([i,hist.Peaks['peaks'][i][0],hist.Peaks['sigDict']['pos'+str(i)]])\n",
    "#print(DataList)\n",
    "ListDF=pd.DataFrame(DataList, columns=['Peak index','TOF Pos','TOF esd'])\n",
    "\n",
    "#ListDF['Dspace Pos']=Dspace_calc(ListDF['TOF Pos'],16324.50,6.86,0.00)\n",
    "ListDF['Dspace Pos']=ListDF.apply(lambda x: Dspace_calc(x['TOF Pos'],16324.50,6.86,0.00), axis=1)\n",
    "ListDF['Dspace esd']=ListDF.apply(lambda x: Dspace_calc(x['TOF Pos']+x['TOF esd'],16324.50,6.86,0.00) - \n",
    "                                      Dspace_calc(x['TOF Pos'],16324.50,6.86,0.00), axis=1)\n",
    "print(ListDF)\n",
    "ListDF.to_csv('GSASPeakFit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  See further down on sequential refinements\n",
    "# Sequential Refinement\n",
    "\n",
    "# gpx.set_Controls('cycles',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
